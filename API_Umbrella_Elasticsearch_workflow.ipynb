{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Elasticsearch URL from environment variable\n",
    "elasticsearch_url = os.environ['ELASTICSEARCH_URL']\n",
    "\n",
    "# Create Elasticsearch client\n",
    "client = Elasticsearch([elasticsearch_url])\n",
    "\n",
    "# Make sure client can connect to Elasticsearch instance\n",
    "client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = Search(using=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = search.count()\n",
    "search = search[0:total]\n",
    "results = search.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = json_normalize(results.hits.hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dataframe columns\n",
    "for column in results_df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of results containing value for each column\n",
    "results_count_sorted = results_df.count().sort_values(ascending=False).iteritems()\n",
    "\n",
    "# Print each metric and value\n",
    "for key, value in results_count_sorted:\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add request_date column by converting request_at column to datetime\n",
    "results_df['request_date'] = pd.to_datetime(results_df['_source.request_at'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use request_date for dataframe index\n",
    "results_df.set_index('request_date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derived column(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to compute some values, based on existing columns. For example, determining whether requests are successful or failure, based on status code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_success_function(row):\n",
    "    \"\"\"\n",
    "    Check if row (request) was successful\n",
    "    Successful means a response with 2xx status\n",
    "    \n",
    "    return True if successful False otherwise\n",
    "    \"\"\"\n",
    "    success = (row['_source.response_status'] >= 200 and row['_source.response_status'] < 300)\n",
    "    \n",
    "    if success:\n",
    "        return 'Success'\n",
    "    else:\n",
    "        return 'Failure'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'Success' column to API Logs\n",
    "# Success is determined by status code, where any status in the 200s is considered successful\n",
    "results_df['Outcome'] = results_df.apply(is_success_function , axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status code indicates whether request was, more or less, successful or failure.\n",
    "\n",
    "- 2xx: success\n",
    "- 3xx: warning\n",
    "- 4xx: fail (client error)\n",
    "- 5xx: fail (server error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count response status codes\n",
    "status_code_value_counts = results_df['_source.response_status'].value_counts()\n",
    "\n",
    "status_code_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted distribution of statuses in the data\n",
    "api_response_code_distributions_plot = status_code_value_counts.plot('bar', title='Response code counts', figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seaborn to produce a countplot of response status codes\n",
    "status_code_counts_plot = sns.countplot(\n",
    "    x='_source.response_status',\n",
    "    data=results_df,\n",
    "    color='teal',\n",
    "    saturation=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success or failure\n",
    "Show the proportion of calls that are successful (2xx) or failure (3xx, 4xx, 5xx)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proxy overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proxy overhead is a measurement of how much latency the proxy adds to a request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.hist(results_df, column='_source.proxy_overhead', bins=15, figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily median proxy overhead\n",
    "daily_median_proxy_overhead = results_df['_source.proxy_overhead'].resample('D').median()\n",
    "\n",
    "# Fill empty values with zero\n",
    "daily_median_proxy_overhead_filled = daily_median_proxy_overhead.fillna(0)\n",
    "\n",
    "daily_median_proxy_overhead_filled.plot(figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
